{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5hvo8QWN-a9"
   },
   "source": [
    "\n",
    "# _fork of fastforwardlabs/whisper-openai:master: colab->UCSD datahub_\n",
    "\n",
    "--\n",
    "\n",
    "<img src=\"https://blog.fastforwardlabs.com/images/cloudera-fast-forward-logo.png\" width=300>\n",
    "\n",
    "# Make your own recordings and transcriptions with OpenAI's Whisper!\n",
    "_a fun diversion brought to you by [Melanie](https://www.linkedin.com/in/melanierbeck/), ML Research Manager at Cloudera Fast Forward Labs_\n",
    "\n",
    "\n",
    "[OpenAI](https://openai.com/) [recently released](https://openai.com/blog/whisper/) Whisper, an automatic speech recognition (ASR) system that was trained on a colossal heap of audio data collected from the web. \n",
    "\n",
    "## What makes Whisper unique? \n",
    "Speech-to-text technology isn't new but Whisper might usher in the  next-generation of ASR systems in terms of the quality and capabilities delivered by a single model (rather than a collection of models, as most ASR systems are today.)  So what makes Whisper special? \n",
    "\n",
    "1. It's \"weakly supervised,\" meaning that it was trained on (audio, transcript) pairs wherein the transcriptions were _not_ human-validated, a typical hallmark of gold-stardard supervised audio datasets.  \n",
    "2. This allows Whisper to be trained on a MASSIVE amount of data scraped from the web (680K hours) -- orders of magnitude larger than most audio datasets (5-30K hours)\n",
    "3. The data contains audio snippets in dozens of languages allowing Whisper to be natively multilingual. \n",
    "4. Whisper is also multitask -- it can perform transcription, translation, voice detection, and language detection. \n",
    "\n",
    "You can learn more about Whisper in OpenAI's [recent post]((https://openai.com/blog/whisper/)), their [paper](https://cdn.openai.com/papers/whisper.pdf), and their open-source [codebase](https://github.com/openai/whisper). In fact, this notebook made use of OpenAI's [LibriSpeech](https://colab.research.google.com/github/openai/whisper/blob/master/notebooks/LibriSpeech.ipynb) Colab example as a starting point, so you should check that out as well!\n",
    "\n",
    "\n",
    "This notebook allows you to play with Whisper by first creating your own audio recording, processing the audio into a format the model will understand, and feeding it into Whisper for translation or transcription! Let's get started. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLdnbL4iRpvB"
   },
   "source": [
    "## Installs and imports \n",
    "The commands below will install the Python packages needed to record audio snippets and use Whisper models for speech-to-text transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZsJUxc0aRsAf"
   },
   "outputs": [],
   "source": [
    "!pip show -qq openai-whisper || pip install --user git+https://github.com/openai/whisper.git sounddevice wavio ipywebrtc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAfgdT6iHnLC"
   },
   "source": [
    "We also need the following in order to record audio from this notebook and process the resulting files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3CqtR2Fi5-vP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import tensorflow  # required in Colab to avoid protobuf compatibility issues\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import whisper\n",
    "import torchaudio\n",
    "\n",
    "from ipywebrtc import AudioRecorder, CameraStream\n",
    "from IPython.display import Audio, display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IMEkgyagYto"
   },
   "source": [
    "## Make your recording\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4pSZkqTH8jR"
   },
   "source": [
    "### Time to record! \n",
    "\n",
    "Press the circle button and start speaking. It may not look it, but the widget will be capturing sound. Click the circle button again when you are finished. The widget will immediately begin to play back what it captured. \n",
    "\n",
    "_If you see \"Loading widget...\" rather than the recording button, try clicking \"Reload\" in your browser to refresh the Jupyterlab session._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107,
     "referenced_widgets": [
      "09446a03c33742dfa70a9f242f96b3be",
      "8964df95ded44ee28b7ed225c564ed9b",
      "823fe8b97ef94aedaed6889ac580c8eb",
      "5604b41fde3b45dd80b954c6128bccf7",
      "09e1f5b2de9945aea20f6129b7c82ec9",
      "35775e7c3c5846a589410566cbec95fa"
     ]
    },
    "id": "-fFdSBBAGjFk",
    "outputId": "5894a254-7fe0-4593-fbee-74491cd72b9f"
   },
   "outputs": [],
   "source": [
    "camera = CameraStream(constraints={'audio': True,'video':False})\n",
    "recorder = AudioRecorder(stream=camera)\n",
    "recorder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dk-zZpPBG25R"
   },
   "source": [
    "The audio format captured above is not readable by PyTorch. In this step, we convert our recording into a format that PyTorch can understand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDDgAohMGrCR"
   },
   "outputs": [],
   "source": [
    "with open('recording.webm', 'wb') as f:\n",
    "    f.write(recorder.audio.value)\n",
    "!ffmpeg -i recording.webm -ac 1 -f wav my_recording.wav -y -hide_banner -loglevel panic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQJhMt6pIgJd"
   },
   "source": [
    "### Alternatively... \n",
    "If you don't want to make your own recording, you can instead upload an audio file to this notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8m2ez4lGrWn"
   },
   "source": [
    "## Select options\n",
    "\n",
    "Whisper is capable of performing transcriptions for many languages (though it performs better for some languages and worse for others.) \n",
    "\n",
    "Whisper is also capable of detecting the input language. However, to be on the safe side, we can explicitly tell Whisper which language to expect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7p2AoJItnIM"
   },
   "outputs": [],
   "source": [
    "language_options = whisper.tokenizer.TO_LANGUAGE_CODE \n",
    "language_list = list(language_options.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "8c4d89ec973647d1a46aa471311e037c",
      "6c5f2af50210411f801f812dc17c389c",
      "90728ace9c454a3ab05ffb3e0bb664a3",
      "b50eded046cf4d378b1d71a186995d21"
     ]
    },
    "id": "dpLnKvlb-vLa",
    "outputId": "bd012b8a-d413-41a9-834a-6674c0e2928a"
   },
   "outputs": [],
   "source": [
    "lang_dropdown = widgets.Dropdown(options=language_list, value='english')\n",
    "output = widgets.Output()\n",
    "display(lang_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EipQBR-INZOW"
   },
   "source": [
    "Whisper is also capable of several tasks, including English-only transcription, Any-to-English translation, and non-English transcription. \n",
    "\n",
    "Below you can select either \"transcription\" (which will yield text in the same language as the input language) or \"translation\" (which will transcribe from non-English to English). \n",
    "\n",
    "![Whisper capabilities](https://cdn.openai.com/whisper/draft-20220920a/asr-training-data-desktop.svg)\n",
    "\n",
    "Image from [Introducing Whisper](https://openai.com/blog/whisper/) by OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "43cdc270c46644b6a0308d3c499601fb",
      "5f9cd9708efb486c930c1397be9a566c",
      "20cdb2181c804215b4a1e6006be77734",
      "fb4b05bd474c409288394cd82d6a9179"
     ]
    },
    "id": "ilyDW-ALMnke",
    "outputId": "4a34e1f6-519c-46e5-a00b-05fbe3540e18"
   },
   "outputs": [],
   "source": [
    "task_dropdown = widgets.Dropdown(options=['transcribe', 'translate'], value='transcribe')\n",
    "output = widgets.Output()\n",
    "display(task_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FG8FN6TQ_ale"
   },
   "source": [
    "## Load Whisper model\n",
    "\n",
    "Whisper comes in five model sizes, four of which also have an optimized English-only version. This notebook loads \"base\"-sized models (bigger than \"tiny\" but smaller than the others), which require about 1GB of RAM. \n",
    "\n",
    "If you selected English above, the cell below will load the optimized English-only version. Otherwise, it will load the multilingual model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_PokfNJtOYNu",
    "outputId": "227e41ec-b1a5-409d-c3c4-20d4564fb09c"
   },
   "outputs": [],
   "source": [
    "if lang_dropdown.value == \"english\":\n",
    "  model = whisper.load_model(\"base.en\")\n",
    "else:\n",
    "  model = whisper.load_model(\"base\")\n",
    "print(\n",
    "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
    "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNrLhTEqP-Q0"
   },
   "source": [
    "Finally, let's set the rest of our task and language options below and see what we've got. Check that your task and language settings are correct, but don't worry about the other defaults. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DwOUHau-dkUt",
    "outputId": "d16eef87-3af5-43e6-b54e-407a2e32f5d8"
   },
   "outputs": [],
   "source": [
    "options = whisper.DecodingOptions(language=lang_dropdown.value, task=task_dropdown.value, without_timestamps=True)\n",
    "options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ns_iOuQpJEHk"
   },
   "source": [
    "## Take Whisper for a test drive\n",
    "\n",
    "All that's left to do now is feed our audio into Whisper. \n",
    "\n",
    "The cell below performs the last processing steps to make this happen. First, it loads our PyTorch-ready audio file. Then it pads the audio into 30 sec segments. It creates a log-mel spectrogram of the audio and this is fed into Whisper along with the options we set above. \n",
    "\n",
    "\n",
    "\n",
    "_Note: if you chose to upload your own audio file rather than create one through this notebook, you'll need to update the audio filename below._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6S0VvoK0vfq"
   },
   "outputs": [],
   "source": [
    "audio = whisper.load_audio(\"my_recording.wav\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "result = model.decode(mel, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "Mg64_MWW1uMb",
    "outputId": "444cfab3-f2bd-4519-9779-3f4aba72d1cc"
   },
   "outputs": [],
   "source": [
    "result.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cHDLtquJNsH"
   },
   "source": [
    "### How well did Whisper do??\n",
    "\n",
    "I read aloud the snippet above from one of my favorite books. For the record, Whisper is pretty dang close, making only two small mistakes -- both on proper names.   "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09446a03c33742dfa70a9f242f96b3be": {
     "model_module": "jupyter-webrtc",
     "model_module_version": "~0.6.0",
     "model_name": "AudioRecorderModel",
     "state": {
      "_data_src": "blob:https://nfrp4p17vqk-496ff2e9c6d22116-0-colab.googleusercontent.com/d984436f-3337-406a-97dd-76a1145ef36f",
      "_dom_classes": [],
      "_model_module": "jupyter-webrtc",
      "_model_module_version": "~0.6.0",
      "_model_name": "AudioRecorderModel",
      "_view_count": null,
      "_view_module": "jupyter-webrtc",
      "_view_module_version": "~0.6.0",
      "_view_name": "AudioRecorderView",
      "audio": "IPY_MODEL_8964df95ded44ee28b7ed225c564ed9b",
      "autosave": false,
      "codecs": "",
      "filename": "record",
      "format": "webm",
      "layout": "IPY_MODEL_823fe8b97ef94aedaed6889ac580c8eb",
      "recording": false,
      "stream": "IPY_MODEL_5604b41fde3b45dd80b954c6128bccf7"
     }
    },
    "09e1f5b2de9945aea20f6129b7c82ec9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20cdb2181c804215b4a1e6006be77734": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35775e7c3c5846a589410566cbec95fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43cdc270c46644b6a0308d3c499601fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "transcribe",
       "translate"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_5f9cd9708efb486c930c1397be9a566c",
      "style": "IPY_MODEL_20cdb2181c804215b4a1e6006be77734"
     }
    },
    "5604b41fde3b45dd80b954c6128bccf7": {
     "model_module": "jupyter-webrtc",
     "model_module_version": "~0.6.0",
     "model_name": "CameraStreamModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "jupyter-webrtc",
      "_model_module_version": "~0.6.0",
      "_model_name": "CameraStreamModel",
      "_view_count": null,
      "_view_module": "jupyter-webrtc",
      "_view_module_version": "~0.6.0",
      "_view_name": "MediaStreamView",
      "constraints": {
       "audio": true,
       "video": false
      },
      "layout": "IPY_MODEL_35775e7c3c5846a589410566cbec95fa"
     }
    },
    "5f9cd9708efb486c930c1397be9a566c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c5f2af50210411f801f812dc17c389c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "823fe8b97ef94aedaed6889ac580c8eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8964df95ded44ee28b7ed225c564ed9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "AudioModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "AudioModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "AudioView",
      "autoplay": true,
      "controls": true,
      "format": "webm",
      "layout": "IPY_MODEL_09e1f5b2de9945aea20f6129b7c82ec9",
      "loop": true
     }
    },
    "8c4d89ec973647d1a46aa471311e037c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "english",
       "chinese",
       "german",
       "spanish",
       "russian",
       "korean",
       "french",
       "japanese",
       "portuguese",
       "turkish",
       "polish",
       "catalan",
       "dutch",
       "arabic",
       "swedish",
       "italian",
       "indonesian",
       "hindi",
       "finnish",
       "vietnamese",
       "hebrew",
       "ukrainian",
       "greek",
       "malay",
       "czech",
       "romanian",
       "danish",
       "hungarian",
       "tamil",
       "norwegian",
       "thai",
       "urdu",
       "croatian",
       "bulgarian",
       "lithuanian",
       "latin",
       "maori",
       "malayalam",
       "welsh",
       "slovak",
       "telugu",
       "persian",
       "latvian",
       "bengali",
       "serbian",
       "azerbaijani",
       "slovenian",
       "kannada",
       "estonian",
       "macedonian",
       "breton",
       "basque",
       "icelandic",
       "armenian",
       "nepali",
       "mongolian",
       "bosnian",
       "kazakh",
       "albanian",
       "swahili",
       "galician",
       "marathi",
       "punjabi",
       "sinhala",
       "khmer",
       "shona",
       "yoruba",
       "somali",
       "afrikaans",
       "occitan",
       "georgian",
       "belarusian",
       "tajik",
       "sindhi",
       "gujarati",
       "amharic",
       "yiddish",
       "lao",
       "uzbek",
       "faroese",
       "haitian creole",
       "pashto",
       "turkmen",
       "nynorsk",
       "maltese",
       "sanskrit",
       "luxembourgish",
       "myanmar",
       "tibetan",
       "tagalog",
       "malagasy",
       "assamese",
       "tatar",
       "hawaiian",
       "lingala",
       "hausa",
       "bashkir",
       "javanese",
       "sundanese",
       "burmese",
       "valencian",
       "flemish",
       "haitian",
       "letzeburgesch",
       "pushto",
       "panjabi",
       "moldavian",
       "moldovan",
       "sinhalese",
       "castilian"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_6c5f2af50210411f801f812dc17c389c",
      "style": "IPY_MODEL_90728ace9c454a3ab05ffb3e0bb664a3"
     }
    },
    "90728ace9c454a3ab05ffb3e0bb664a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b50eded046cf4d378b1d71a186995d21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb4b05bd474c409288394cd82d6a9179": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
